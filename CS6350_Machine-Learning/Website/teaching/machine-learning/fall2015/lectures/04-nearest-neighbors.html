<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Nearest Neighbor Classification | Machine Learning |
    Fall 2015</title>
    <meta name="description" content="Machine learning (CS 5350/CS 6350), Fall 2015
">

    <link rel="stylesheet" href="../css/style.css">
    <link rel="stylesheet" href="../css/extra.css">    
    <link rel="canonical" href="04-nearest-neighbors.html">
</head>

  
  <body>
    <div id="content">
      <header class="top">
  <h1 class="title">
    <a href="../index.html" style="text-decoration:none">Machine Learning</a>
  </h1>
  <div id="title-email"">CS 5350/6350, Fall 2015</div>  
</header>


        <hr/>
<center>
  <div class="nav">
    <ul>
      <li><a href="../index.html">home</a></li>
      <li><a href="../info.html">information</a></li>
      <li><a href="../topics.html">topics</a></li>
      <li><a href="../lectures.html">lectures</a></li>
      <li><a href="../assignments.html">homeworks</a></li>
      <li><a href="../projects.html">projects</a></li>
      <li><a href="../resources.html">resources</a></li>
    </ul>
  </div>
</center>
        
        <div class="main">
           <h2> Nearest Neighbor Classification</h2> 
          <div class="post" style="margin-top:1em;">

  <center style="font-size:80%; margin-top:1em">
    
    <a href="03-decision-trees.html">&larr;Previous lecture</a>
     &nbsp;|&nbsp;
    <a href="../index.html">Home</a> &nbsp;|&nbsp;
    
    <a href="05-linear-classifiers.html">Next lecture &rarr;</a>    
        
  </center>
  
  
  <p>In this lecture, we look at the popular K nearest neighbors algorithm,
which is an example of instance based learning. We see how the nearest
neighbors algorithm carves up the instance space into Voronoi maps and
can express rather complicated decision boundaries. We will end with a
discussion about the curse of dimensionality.</p>

<h3 id="links-and-resources">Links and Resources</h3>

<ul>
  <li>
    <p><a href="../slides/04-nearest-neighbors/nearest-neighbors.pdf">Lecture slides</a></p>
  </li>
  <li>
    <p>Chapter 13 of
<a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/">The Elements of Statistical Learning</a>
discusses nearest neighbors. Section 5 of chapter 2 talks about the
curse of dimensionality. (Contents available online)</p>
  </li>
  <li>
    <p>Chapter 8 of Tom Mitchell’s textbook</p>
  </li>
  <li>
    <p>Chapter 2 of Hal Daumé III,
<a href="http://ciml.info/">A Course in Machine Learning</a> (available online)</p>
  </li>
</ul>

<h3 id="miscellaneous">Miscellaneous</h3>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Flatland">Flatland: A Romance of Many Dimensions</a>,
a 1884 novella that serves as a fun introduction to multiple
dimensions. The link points to the Wikipedia page for the book. The
actual source of the book is also available online. See the links at
the bottom of the Wikipedia page.</li>
</ul>


  <center style="font-size:80%; margin-top:1em">
    
    <a href="03-decision-trees.html">&larr;Previous lecture</a>
     &nbsp;|&nbsp;
    <a href="../index.html">Home</a> &nbsp;|&nbsp;
    
    <a href="05-linear-classifiers.html">Next lecture &rarr;</a>    
        
  </center>
</div>

        </div>
        <hr/>
<center>
  <div class="nav">
    <ul>
      <li><a href="../index.html">home</a></li>
      <li><a href="../info.html">information</a></li>
      <li><a href="../topics.html">topics</a></li>
      <li><a href="../lectures.html">lectures</a></li>
      <li><a href="../assignments.html">homeworks</a></li>
      <li><a href="../projects.html">projects</a></li>
      <li><a href="../resources.html">resources</a></li>
    </ul>
  </div>
</center>


    </div>
  </body>
</html>
